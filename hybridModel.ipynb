{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tcn import TCN\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"myData2.parquet\"\n",
    "df = pd.read_parquet(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['timestamp_seconds', # lowers the accuracy \n",
    "                     'node_memory_Percpu_bytes', \n",
    "                     'node_context_switches_total', \n",
    "                     'surfsara_power_usage', \n",
    "                     'node_netstat_Tcp_InSegs', \n",
    "                     'node_netstat_Tcp_OutSegs', \n",
    "                     'node_network_transmit_packets_total-sum', \n",
    "                     'node_filesystem_size_bytes-sum', \n",
    "                     'node_filesystem_files-sum', \n",
    "                     'node_memory_MemFree_bytes', \n",
    "                     'node_netstat_Tcp_InErrs']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column 'failed_jobs' representing the target variable\n",
    "df['failed_jobs'] = (df['state'] == 'FAILED').astype(int)\n",
    "\n",
    "# Extract relevant columns\n",
    "df_selected = df[['timestamp', 'state'] + selected_features].copy()\n",
    "\n",
    "# Encode the target variable 'state' to binary (0 for \"COMPLETED\", 1 otherwise)\n",
    "df_selected['target'] = (df_selected['state'] != 'COMPLETED').astype(int)\n",
    "\n",
    "# Drop the original 'state' column\n",
    "df_selected.drop('state', axis=1, inplace=True)\n",
    "\n",
    "# Define time intervals\n",
    "time_intervals = {'minute': '1T', 'hour': '1H', 'day': '1D'}\n",
    "\n",
    "# Normalize selected features\n",
    "scaler = MinMaxScaler()\n",
    "df_selected[selected_features] = scaler.fit_transform(df_selected[selected_features])\n",
    "\n",
    "# Set sequence length\n",
    "sequence_length = 30\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to prepare data\n",
    "def prepare_data(data, time_interval):\n",
    "    data.set_index('timestamp', inplace=True) # FixMe\n",
    "    data_resampled = data.resample(time_interval).sum()\n",
    "    data_resampled['target'] = data_resampled['target'].clip(upper=1)  # Clip values to 1\n",
    "    return data_resampled\n",
    "\n",
    "# Function to create sequences\n",
    "def create_sequences(data, sequence_length):\n",
    "    sequences, targets = [], []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        seq = data.iloc[i:i+sequence_length].values\n",
    "        target = data.iloc[i+sequence_length]['target']\n",
    "        sequences.append(seq)\n",
    "        targets.append(target)\n",
    "    return np.array(sequences), np.array(targets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data with hourly intervals\n",
    "data_hour = prepare_data(df_selected, time_intervals['hour'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences and targets\n",
    "sequences_hour, targets_hour = create_sequences(data_hour, sequence_length)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_hour, X_test_hour, y_train_hour, y_test_hour = train_test_split(sequences_hour, targets_hour, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LSTM model\n",
    "lstm_model_hour = Sequential()\n",
    "lstm_model_hour.add(LSTM(50, input_shape=(X_train_hour.shape[1], X_train_hour.shape[2])))\n",
    "lstm_model_hour.add(Dense(1, activation='sigmoid'))\n",
    "lstm_model_hour.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "54/54 [==============================] - 4s 32ms/step - loss: 0.4068 - mean_absolute_error: 0.4068 - val_loss: 0.3304 - val_mean_absolute_error: 0.3304\n",
      "Epoch 2/20\n",
      "54/54 [==============================] - 1s 22ms/step - loss: 0.3167 - mean_absolute_error: 0.3167 - val_loss: 0.2593 - val_mean_absolute_error: 0.2593\n",
      "Epoch 3/20\n",
      "54/54 [==============================] - 1s 22ms/step - loss: 0.2706 - mean_absolute_error: 0.2706 - val_loss: 0.2182 - val_mean_absolute_error: 0.2182\n",
      "Epoch 4/20\n",
      "54/54 [==============================] - 1s 22ms/step - loss: 0.2419 - mean_absolute_error: 0.2419 - val_loss: 0.2034 - val_mean_absolute_error: 0.2034\n",
      "Epoch 5/20\n",
      "54/54 [==============================] - 1s 22ms/step - loss: 0.2208 - mean_absolute_error: 0.2208 - val_loss: 0.1770 - val_mean_absolute_error: 0.1770\n",
      "Epoch 6/20\n",
      "54/54 [==============================] - 1s 22ms/step - loss: 0.1988 - mean_absolute_error: 0.1988 - val_loss: 0.1692 - val_mean_absolute_error: 0.1692\n",
      "Epoch 7/20\n",
      "54/54 [==============================] - 1s 22ms/step - loss: 0.1831 - mean_absolute_error: 0.1831 - val_loss: 0.1563 - val_mean_absolute_error: 0.1563\n",
      "Epoch 8/20\n",
      "54/54 [==============================] - 1s 22ms/step - loss: 0.1676 - mean_absolute_error: 0.1676 - val_loss: 0.1546 - val_mean_absolute_error: 0.1546\n",
      "Epoch 9/20\n",
      "54/54 [==============================] - 1s 21ms/step - loss: 0.1592 - mean_absolute_error: 0.1592 - val_loss: 0.1376 - val_mean_absolute_error: 0.1376\n",
      "Epoch 10/20\n",
      "54/54 [==============================] - 1s 22ms/step - loss: 0.1503 - mean_absolute_error: 0.1503 - val_loss: 0.1321 - val_mean_absolute_error: 0.1321\n",
      "Epoch 11/20\n",
      "54/54 [==============================] - 1s 22ms/step - loss: 0.1407 - mean_absolute_error: 0.1407 - val_loss: 0.1279 - val_mean_absolute_error: 0.1279\n",
      "Epoch 12/20\n",
      "54/54 [==============================] - 1s 22ms/step - loss: 0.1361 - mean_absolute_error: 0.1361 - val_loss: 0.1218 - val_mean_absolute_error: 0.1218\n",
      "Epoch 13/20\n",
      "54/54 [==============================] - 1s 22ms/step - loss: 0.1328 - mean_absolute_error: 0.1328 - val_loss: 0.1168 - val_mean_absolute_error: 0.1168\n",
      "Epoch 14/20\n",
      "54/54 [==============================] - 1s 22ms/step - loss: 0.1280 - mean_absolute_error: 0.1280 - val_loss: 0.1092 - val_mean_absolute_error: 0.1092\n",
      "Epoch 15/20\n",
      "54/54 [==============================] - 1s 22ms/step - loss: 0.1190 - mean_absolute_error: 0.1190 - val_loss: 0.1056 - val_mean_absolute_error: 0.1056\n",
      "Epoch 16/20\n",
      "54/54 [==============================] - 1s 22ms/step - loss: 0.1199 - mean_absolute_error: 0.1199 - val_loss: 0.1083 - val_mean_absolute_error: 0.1083\n",
      "Epoch 17/20\n",
      "54/54 [==============================] - 1s 22ms/step - loss: 0.1195 - mean_absolute_error: 0.1195 - val_loss: 0.1038 - val_mean_absolute_error: 0.1038\n",
      "Epoch 18/20\n",
      "54/54 [==============================] - 1s 21ms/step - loss: 0.1141 - mean_absolute_error: 0.1141 - val_loss: 0.0915 - val_mean_absolute_error: 0.0915\n",
      "Epoch 19/20\n",
      "54/54 [==============================] - 1s 22ms/step - loss: 0.1117 - mean_absolute_error: 0.1117 - val_loss: 0.0965 - val_mean_absolute_error: 0.0965\n",
      "Epoch 20/20\n",
      "54/54 [==============================] - 1s 22ms/step - loss: 0.1075 - mean_absolute_error: 0.1075 - val_loss: 0.0914 - val_mean_absolute_error: 0.0914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f9ff556d390>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "lstm_model_hour.fit(X_train_hour, y_train_hour, epochs=20, batch_size=32, validation_split=0.1, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the TCN model\n",
    "tcn_model_hour = Sequential([\n",
    "    TCN(input_shape=(sequence_length, X_train_hour.shape[2])),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "54/54 [==============================] - 5s 46ms/step - loss: 0.5403 - mean_absolute_error: 0.5403 - val_loss: 0.4245 - val_mean_absolute_error: 0.4245\n",
      "Epoch 2/20\n",
      "54/54 [==============================] - 2s 37ms/step - loss: 0.4514 - mean_absolute_error: 0.4514 - val_loss: 0.4293 - val_mean_absolute_error: 0.4293\n",
      "Epoch 3/20\n",
      "54/54 [==============================] - 2s 38ms/step - loss: 0.4514 - mean_absolute_error: 0.4514 - val_loss: 0.4293 - val_mean_absolute_error: 0.4293\n",
      "Epoch 4/20\n",
      "54/54 [==============================] - 2s 37ms/step - loss: 0.4514 - mean_absolute_error: 0.4514 - val_loss: 0.4293 - val_mean_absolute_error: 0.4293\n",
      "Epoch 5/20\n",
      "54/54 [==============================] - 2s 37ms/step - loss: 0.4514 - mean_absolute_error: 0.4514 - val_loss: 0.4293 - val_mean_absolute_error: 0.4293\n",
      "Epoch 6/20\n",
      "54/54 [==============================] - 2s 35ms/step - loss: 0.4514 - mean_absolute_error: 0.4514 - val_loss: 0.4293 - val_mean_absolute_error: 0.4293\n",
      "Epoch 7/20\n",
      "54/54 [==============================] - 2s 37ms/step - loss: 0.4514 - mean_absolute_error: 0.4514 - val_loss: 0.4293 - val_mean_absolute_error: 0.4293\n",
      "Epoch 8/20\n",
      "54/54 [==============================] - 2s 35ms/step - loss: 0.4514 - mean_absolute_error: 0.4514 - val_loss: 0.4293 - val_mean_absolute_error: 0.4293\n",
      "Epoch 9/20\n",
      "54/54 [==============================] - 2s 35ms/step - loss: 0.4514 - mean_absolute_error: 0.4514 - val_loss: 0.4293 - val_mean_absolute_error: 0.4293\n",
      "Epoch 10/20\n",
      "54/54 [==============================] - 2s 36ms/step - loss: 0.4514 - mean_absolute_error: 0.4514 - val_loss: 0.4293 - val_mean_absolute_error: 0.4293\n",
      "Epoch 11/20\n",
      "54/54 [==============================] - 2s 36ms/step - loss: 0.4514 - mean_absolute_error: 0.4514 - val_loss: 0.4293 - val_mean_absolute_error: 0.4293\n",
      "Epoch 12/20\n",
      "54/54 [==============================] - 2s 36ms/step - loss: 0.4514 - mean_absolute_error: 0.4514 - val_loss: 0.4293 - val_mean_absolute_error: 0.4293\n",
      "Epoch 13/20\n",
      "54/54 [==============================] - 2s 36ms/step - loss: 0.4514 - mean_absolute_error: 0.4514 - val_loss: 0.4293 - val_mean_absolute_error: 0.4293\n",
      "Epoch 14/20\n",
      "54/54 [==============================] - 2s 36ms/step - loss: 0.4514 - mean_absolute_error: 0.4514 - val_loss: 0.4293 - val_mean_absolute_error: 0.4293\n",
      "Epoch 15/20\n",
      "54/54 [==============================] - 2s 35ms/step - loss: 0.4514 - mean_absolute_error: 0.4514 - val_loss: 0.4293 - val_mean_absolute_error: 0.4293\n",
      "Epoch 16/20\n",
      "54/54 [==============================] - 2s 35ms/step - loss: 0.4514 - mean_absolute_error: 0.4514 - val_loss: 0.4293 - val_mean_absolute_error: 0.4293\n",
      "Epoch 17/20\n",
      "54/54 [==============================] - 2s 35ms/step - loss: 0.4514 - mean_absolute_error: 0.4514 - val_loss: 0.4293 - val_mean_absolute_error: 0.4293\n",
      "Epoch 18/20\n",
      "54/54 [==============================] - 2s 35ms/step - loss: 0.4514 - mean_absolute_error: 0.4514 - val_loss: 0.4293 - val_mean_absolute_error: 0.4293\n",
      "Epoch 19/20\n",
      "54/54 [==============================] - 2s 36ms/step - loss: 0.4514 - mean_absolute_error: 0.4514 - val_loss: 0.4293 - val_mean_absolute_error: 0.4293\n",
      "Epoch 20/20\n",
      "54/54 [==============================] - 2s 36ms/step - loss: 0.4514 - mean_absolute_error: 0.4514 - val_loss: 0.4293 - val_mean_absolute_error: 0.4293\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f9fd857b910>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model\n",
    "tcn_model_hour.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "\n",
    "# Train the model\n",
    "tcn_model_hour.fit(X_train_hour, y_train_hour, epochs=20, batch_size=32, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble Model combining LSTM and TCN\n",
    "def create_hybrid_model(lstm_model, tcn_model):\n",
    "    lstm_input = lstm_model.input\n",
    "    tcn_input = tcn_model.input\n",
    "\n",
    "    # Get the output layers of both models\n",
    "    lstm_output = lstm_model.layers[-1].output\n",
    "    tcn_output = tcn_model.layers[-1].output\n",
    "\n",
    "    # Concatenate the outputs\n",
    "    merged = concatenate([lstm_output, tcn_output])\n",
    "\n",
    "    # Add a dense layer for final prediction\n",
    "    merged = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "    # Create the ensemble model\n",
    "    ensemble_model = Model(inputs=[lstm_input, tcn_input], outputs=merged)\n",
    "\n",
    "    # Compile the model\n",
    "    ensemble_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "\n",
    "    return ensemble_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "54/54 [==============================] - 7s 53ms/step - loss: 0.4068 - mean_absolute_error: 0.4068 - val_loss: 0.4052 - val_mean_absolute_error: 0.4052\n",
      "Epoch 2/20\n",
      "54/54 [==============================] - 2s 38ms/step - loss: 0.3954 - mean_absolute_error: 0.3954 - val_loss: 0.3930 - val_mean_absolute_error: 0.3930\n",
      "Epoch 3/20\n",
      "54/54 [==============================] - 2s 38ms/step - loss: 0.3843 - mean_absolute_error: 0.3843 - val_loss: 0.3823 - val_mean_absolute_error: 0.3823\n",
      "Epoch 4/20\n",
      "54/54 [==============================] - 2s 38ms/step - loss: 0.3757 - mean_absolute_error: 0.3757 - val_loss: 0.3720 - val_mean_absolute_error: 0.3720\n",
      "Epoch 5/20\n",
      "54/54 [==============================] - 2s 37ms/step - loss: 0.3655 - mean_absolute_error: 0.3655 - val_loss: 0.3613 - val_mean_absolute_error: 0.3613\n",
      "Epoch 6/20\n",
      "54/54 [==============================] - 2s 37ms/step - loss: 0.3588 - mean_absolute_error: 0.3588 - val_loss: 0.3559 - val_mean_absolute_error: 0.3559\n",
      "Epoch 7/20\n",
      "54/54 [==============================] - 2s 37ms/step - loss: 0.3520 - mean_absolute_error: 0.3520 - val_loss: 0.3461 - val_mean_absolute_error: 0.3461\n",
      "Epoch 8/20\n",
      "54/54 [==============================] - 2s 37ms/step - loss: 0.3451 - mean_absolute_error: 0.3451 - val_loss: 0.3410 - val_mean_absolute_error: 0.3410\n",
      "Epoch 9/20\n",
      "54/54 [==============================] - 2s 37ms/step - loss: 0.3405 - mean_absolute_error: 0.3405 - val_loss: 0.3384 - val_mean_absolute_error: 0.3384\n",
      "Epoch 10/20\n",
      "54/54 [==============================] - 2s 38ms/step - loss: 0.3332 - mean_absolute_error: 0.3332 - val_loss: 0.3326 - val_mean_absolute_error: 0.3326\n",
      "Epoch 11/20\n",
      "54/54 [==============================] - 2s 38ms/step - loss: 0.3315 - mean_absolute_error: 0.3315 - val_loss: 0.3333 - val_mean_absolute_error: 0.3333\n",
      "Epoch 12/20\n",
      "54/54 [==============================] - 2s 37ms/step - loss: 0.3271 - mean_absolute_error: 0.3271 - val_loss: 0.3287 - val_mean_absolute_error: 0.3287\n",
      "Epoch 13/20\n",
      "54/54 [==============================] - 2s 38ms/step - loss: 0.3201 - mean_absolute_error: 0.3201 - val_loss: 0.3276 - val_mean_absolute_error: 0.3276\n",
      "Epoch 14/20\n",
      "54/54 [==============================] - 2s 37ms/step - loss: 0.3179 - mean_absolute_error: 0.3179 - val_loss: 0.3092 - val_mean_absolute_error: 0.3092\n",
      "Epoch 15/20\n",
      "54/54 [==============================] - 2s 38ms/step - loss: 0.3125 - mean_absolute_error: 0.3125 - val_loss: 0.3032 - val_mean_absolute_error: 0.3032\n",
      "Epoch 16/20\n",
      "54/54 [==============================] - 2s 37ms/step - loss: 0.3086 - mean_absolute_error: 0.3086 - val_loss: 0.2977 - val_mean_absolute_error: 0.2977\n",
      "Epoch 17/20\n",
      "54/54 [==============================] - 2s 39ms/step - loss: 0.3037 - mean_absolute_error: 0.3037 - val_loss: 0.2951 - val_mean_absolute_error: 0.2951\n",
      "Epoch 18/20\n",
      "54/54 [==============================] - 2s 38ms/step - loss: 0.2995 - mean_absolute_error: 0.2995 - val_loss: 0.2943 - val_mean_absolute_error: 0.2943\n",
      "Epoch 19/20\n",
      "54/54 [==============================] - 2s 37ms/step - loss: 0.2974 - mean_absolute_error: 0.2974 - val_loss: 0.2908 - val_mean_absolute_error: 0.2908\n",
      "Epoch 20/20\n",
      "54/54 [==============================] - 2s 37ms/step - loss: 0.2918 - mean_absolute_error: 0.2918 - val_loss: 0.2829 - val_mean_absolute_error: 0.2829\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f9f18214ed0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the hybrid model\n",
    "hybrid_model_hour = create_hybrid_model(lstm_model_hour, tcn_model_hour)\n",
    "\n",
    "# Train the hybrid model with both LSTM and TCN data\n",
    "hybrid_model_hour.fit([X_train_hour, X_train_hour], y_train_hour, epochs=20, batch_size=32, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Mean Absolute Error: 0.2857\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using Mean Absolute Error\n",
    "mae_hour = hybrid_model_hour.evaluate([X_test_hour, X_test_hour], y_test_hour, verbose=0)[1]\n",
    "print(f'Model Mean Absolute Error: {mae_hour:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 763ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Predicted Failures for the Next 7 Time Steps (Hybrid):\n",
      "[0.18681437, 0.18678875, 0.18677297, 0.18677317, 0.18677296, 0.18677284, 0.18677321]\n",
      "Mean Absolute Error for Predictions: 0.5448\n"
     ]
    }
   ],
   "source": [
    "# Function to make predictions on new data for the hybrid model\n",
    "def predict_future_failures_hybrid(model, input_data_lstm, input_data_tcn, sequence_length, prediction_steps):\n",
    "    predictions = []\n",
    "\n",
    "    for _ in range(prediction_steps):\n",
    "        # Make predictions for the next time step using both LSTM and TCN models\n",
    "        prediction = model.predict([input_data_lstm.reshape(1, sequence_length, input_data_lstm.shape[1]),\n",
    "                                    input_data_tcn.reshape(1, sequence_length, input_data_tcn.shape[1])])\n",
    "        predictions.append(prediction[0, 0])\n",
    "\n",
    "        # Shift the input data by one time step and append the new prediction\n",
    "        input_data_lstm = np.roll(input_data_lstm, shift=-1, axis=0)\n",
    "        input_data_lstm[-1, -1] = prediction[0, 0]\n",
    "\n",
    "        input_data_tcn = np.roll(input_data_tcn, shift=-1, axis=0)\n",
    "        input_data_tcn[-1, -1] = prediction[0, 0]\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# Select a starting point for predictions\n",
    "input_data_lstm_hybrid = X_test_hour[10]\n",
    "input_data_tcn_hybrid = X_test_hour[10]\n",
    "\n",
    "# Number of time steps to predict into the future\n",
    "prediction_steps_hybrid = 7\n",
    "\n",
    "# Make predictions with the hybrid model\n",
    "predicted_failures_hybrid = predict_future_failures_hybrid(hybrid_model_hour, input_data_lstm_hybrid, input_data_tcn_hybrid, sequence_length, prediction_steps_hybrid)\n",
    "\n",
    "# Print the predicted failures\n",
    "print(\"Predicted Failures for the Next 7 Time Steps (Hybrid):\")\n",
    "print(predicted_failures_hybrid)\n",
    "\n",
    "# Evaluate the predictions using Mean Absolute Error\n",
    "mae_predictions_hybrid = np.mean(np.abs(predicted_failures_hybrid - y_test_hour[10:10+prediction_steps_hybrid]))\n",
    "print(f'Mean Absolute Error for Predictions: {mae_predictions_hybrid:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
