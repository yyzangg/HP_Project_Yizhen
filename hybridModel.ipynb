{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-16 16:37:52.033583: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-16 16:37:52.077461: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-16 16:37:52.077496: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-16 16:37:52.077521: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-16 16:37:52.085571: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-16 16:37:52.929423: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Concatenate, Attention\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tcn import TCN\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"myData2.parquet\"\n",
    "df = pd.read_parquet(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['timestamp_seconds',\n",
    "                     'node_memory_Percpu_bytes', \n",
    "                     'node_context_switches_total', \n",
    "                     'surfsara_power_usage', \n",
    "                     'node_netstat_Tcp_InSegs', \n",
    "                     'node_netstat_Tcp_OutSegs', \n",
    "                     'node_network_transmit_packets_total-sum', \n",
    "                     'node_filesystem_size_bytes-sum', \n",
    "                     'node_filesystem_files-sum', \n",
    "                     'node_memory_MemFree_bytes', \n",
    "                     'node_netstat_Tcp_InErrs']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract relevant columns\n",
    "df_selected = df[['timestamp', 'state'] + selected_features].copy()\n",
    "\n",
    "# Encode the target variable 'state' to binary (0 for \"COMPLETED\", 1 otherwise)\n",
    "df_selected['target'] = (df_selected['state'] != 'COMPLETED').astype(int)\n",
    "\n",
    "# Drop the original 'state' column\n",
    "df_selected.drop('state', axis=1, inplace=True)\n",
    "\n",
    "# Define time intervals\n",
    "time_intervals = {'minute': '1T', 'hour': '1H', 'day': '1D'}\n",
    "\n",
    "# Normalize selected features\n",
    "scaler = MinMaxScaler()\n",
    "df_selected[selected_features] = scaler.fit_transform(df_selected[selected_features])\n",
    "\n",
    "# Set sequence length\n",
    "sequence_length = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to prepare data\n",
    "def prepare_data(data, time_interval):\n",
    "    data.set_index('timestamp', inplace=True)\n",
    "    data_resampled = data.resample(time_interval).sum()\n",
    "    data_resampled['target'] = data_resampled['target'].clip(upper=1)  # Clip values to 1\n",
    "    return data_resampled\n",
    "\n",
    "# Function to create sequences\n",
    "def create_sequences(data, sequence_length):\n",
    "    sequences, targets = [], []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        seq = data.iloc[i:i+sequence_length].values\n",
    "        target = data.iloc[i+sequence_length]['target']\n",
    "        sequences.append(seq)\n",
    "        targets.append(target)\n",
    "    return np.array(sequences), np.array(targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make predictions on new data for the hybrid model\n",
    "def predict_future_failures_hybrid(model, input_data_lstm, input_data_tcn, sequence_length, prediction_steps):\n",
    "    predictions = []\n",
    "\n",
    "    for _ in range(prediction_steps):\n",
    "        # Make predictions for the next time step using both LSTM and TCN models\n",
    "        prediction = model.predict([input_data_lstm.reshape(1, sequence_length, input_data_lstm.shape[1]),\n",
    "                                    input_data_tcn.reshape(1, sequence_length, input_data_tcn.shape[1])])\n",
    "        predictions.append(prediction[0, 0])\n",
    "\n",
    "        # Shift the input data by one time step and append the new prediction\n",
    "        input_data_lstm = np.roll(input_data_lstm, shift=-1, axis=0)\n",
    "        input_data_lstm[-1, -1] = prediction[0, 0]\n",
    "\n",
    "        input_data_tcn = np.roll(input_data_tcn, shift=-1, axis=0)\n",
    "        input_data_tcn[-1, -1] = prediction[0, 0]\n",
    "\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 3s 206ms/step - loss: 0.3050 - mean_squared_error: 0.3050 - val_loss: 0.2726 - val_mean_squared_error: 0.2726\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.2713 - mean_squared_error: 0.2713 - val_loss: 0.2297 - val_mean_squared_error: 0.2297\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.2432 - mean_squared_error: 0.2432 - val_loss: 0.2124 - val_mean_squared_error: 0.2124\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.2064 - mean_squared_error: 0.2064 - val_loss: 0.1574 - val_mean_squared_error: 0.1574\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.1876 - mean_squared_error: 0.1876 - val_loss: 0.1351 - val_mean_squared_error: 0.1351\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.1703 - mean_squared_error: 0.1703 - val_loss: 0.1123 - val_mean_squared_error: 0.1123\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.1629 - mean_squared_error: 0.1629 - val_loss: 0.1103 - val_mean_squared_error: 0.1103\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.1575 - mean_squared_error: 0.1575 - val_loss: 0.1163 - val_mean_squared_error: 0.1163\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.1581 - mean_squared_error: 0.1581 - val_loss: 0.1091 - val_mean_squared_error: 0.1091\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.1557 - mean_squared_error: 0.1557 - val_loss: 0.1036 - val_mean_squared_error: 0.1036\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 3s 513ms/step - loss: 0.6885 - mean_squared_error: 0.6885 - val_loss: 0.8571 - val_mean_squared_error: 0.8571\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.6885 - mean_squared_error: 0.6885 - val_loss: 0.8571 - val_mean_squared_error: 0.8571\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.6885 - mean_squared_error: 0.6885 - val_loss: 0.8571 - val_mean_squared_error: 0.8571\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.6885 - mean_squared_error: 0.6885 - val_loss: 0.8571 - val_mean_squared_error: 0.8571\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.6885 - mean_squared_error: 0.6885 - val_loss: 0.8571 - val_mean_squared_error: 0.8571\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.6885 - mean_squared_error: 0.6885 - val_loss: 0.8571 - val_mean_squared_error: 0.8571\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.6885 - mean_squared_error: 0.6885 - val_loss: 0.8571 - val_mean_squared_error: 0.8571\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.6885 - mean_squared_error: 0.6885 - val_loss: 0.8571 - val_mean_squared_error: 0.8571\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.6885 - mean_squared_error: 0.6885 - val_loss: 0.8571 - val_mean_squared_error: 0.8571\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.6885 - mean_squared_error: 0.6885 - val_loss: 0.8571 - val_mean_squared_error: 0.8571\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.6885 - mean_squared_error: 0.6885 - val_loss: 0.8571 - val_mean_squared_error: 0.8571\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.6885 - mean_squared_error: 0.6885 - val_loss: 0.8571 - val_mean_squared_error: 0.8571\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.6885 - mean_squared_error: 0.6885 - val_loss: 0.8571 - val_mean_squared_error: 0.8571\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6885 - mean_squared_error: 0.6885 - val_loss: 0.8571 - val_mean_squared_error: 0.8571\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6885 - mean_squared_error: 0.6885 - val_loss: 0.8571 - val_mean_squared_error: 0.8571\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.6885 - mean_squared_error: 0.6885 - val_loss: 0.8571 - val_mean_squared_error: 0.8571\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.6885 - mean_squared_error: 0.6885 - val_loss: 0.8571 - val_mean_squared_error: 0.8571\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.6885 - mean_squared_error: 0.6885 - val_loss: 0.8571 - val_mean_squared_error: 0.8571\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.6885 - mean_squared_error: 0.6885 - val_loss: 0.8571 - val_mean_squared_error: 0.8571\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.6885 - mean_squared_error: 0.6885 - val_loss: 0.8571 - val_mean_squared_error: 0.8571\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 5s 879ms/step - loss: 0.1989 - mean_squared_error: 0.1989 - val_loss: 0.1545 - val_mean_squared_error: 0.1545\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.2008 - mean_squared_error: 0.2008 - val_loss: 0.1523 - val_mean_squared_error: 0.1523\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.2006 - mean_squared_error: 0.2006 - val_loss: 0.1596 - val_mean_squared_error: 0.1596\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.2009 - mean_squared_error: 0.2009 - val_loss: 0.1527 - val_mean_squared_error: 0.1527\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.1999 - mean_squared_error: 0.1999 - val_loss: 0.1524 - val_mean_squared_error: 0.1524\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.1992 - mean_squared_error: 0.1992 - val_loss: 0.1518 - val_mean_squared_error: 0.1518\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.1998 - mean_squared_error: 0.1998 - val_loss: 0.1503 - val_mean_squared_error: 0.1503\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.1977 - mean_squared_error: 0.1977 - val_loss: 0.1495 - val_mean_squared_error: 0.1495\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.1970 - mean_squared_error: 0.1970 - val_loss: 0.1488 - val_mean_squared_error: 0.1488\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.1963 - mean_squared_error: 0.1963 - val_loss: 0.1482 - val_mean_squared_error: 0.1482\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.1948 - mean_squared_error: 0.1948 - val_loss: 0.1486 - val_mean_squared_error: 0.1486\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.1947 - mean_squared_error: 0.1947 - val_loss: 0.1483 - val_mean_squared_error: 0.1483\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.1936 - mean_squared_error: 0.1936 - val_loss: 0.1466 - val_mean_squared_error: 0.1466\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.1940 - mean_squared_error: 0.1940 - val_loss: 0.1459 - val_mean_squared_error: 0.1459\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.1935 - mean_squared_error: 0.1935 - val_loss: 0.1454 - val_mean_squared_error: 0.1454\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.1928 - mean_squared_error: 0.1928 - val_loss: 0.1446 - val_mean_squared_error: 0.1446\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.1921 - mean_squared_error: 0.1921 - val_loss: 0.1440 - val_mean_squared_error: 0.1440\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.1915 - mean_squared_error: 0.1915 - val_loss: 0.1441 - val_mean_squared_error: 0.1441\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.1909 - mean_squared_error: 0.1909 - val_loss: 0.1434 - val_mean_squared_error: 0.1434\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.1911 - mean_squared_error: 0.1911 - val_loss: 0.1423 - val_mean_squared_error: 0.1423\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f34244a1250>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare data with daily intervals\n",
    "data_day = prepare_data(df_selected, time_intervals['day'])\n",
    "\n",
    "# Create sequences and targets\n",
    "sequences_day, targets_day = create_sequences(data_day, sequence_length)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_day, X_test_day, y_train_day, y_test_day = train_test_split(sequences_day, targets_day, test_size=0.2, random_state=1)\n",
    "\n",
    "# Build the LSTM model\n",
    "lstm_model_day = Sequential()\n",
    "lstm_model_day.add(LSTM(50, input_shape=(X_train_day.shape[1], X_train_day.shape[2])))\n",
    "lstm_model_day.add(Dense(1, activation='sigmoid'))\n",
    "lstm_model_day.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
    "\n",
    "# Train the model\n",
    "lstm_model_day.fit(X_train_day, y_train_day, epochs=10, batch_size=16, validation_split=0.15)\n",
    "\n",
    "# Build the TCN model\n",
    "tcn_model_day = Sequential([\n",
    "    TCN(input_shape=(sequence_length, X_train_day.shape[2])),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "tcn_model_day.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
    "\n",
    "# Train the model\n",
    "tcn_model_day.fit(X_train_day, y_train_day, epochs=20, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Function to create a hybrid model with attention mechanism\n",
    "def create_attention_hybrid_model(lstm_model, tcn_model):\n",
    "    lstm_input = lstm_model.input\n",
    "    tcn_input = tcn_model.input\n",
    "\n",
    "    # Get the output layers of both models\n",
    "    lstm_output = lstm_model.layers[-1].output\n",
    "    tcn_output = tcn_model.layers[-1].output\n",
    "\n",
    "    # Use Attention mechanism to combine outputs\n",
    "    attention = Attention()([lstm_output, tcn_output])\n",
    "    merged = Concatenate()([lstm_output, tcn_output, attention])\n",
    "\n",
    "    # Add a dense layer for the final prediction\n",
    "    merged = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "    # Create the ensemble model\n",
    "    ensemble_model = Model(inputs=[lstm_input, tcn_input], outputs=merged)\n",
    "\n",
    "    # Compile the model\n",
    "    ensemble_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
    "\n",
    "    return ensemble_model\n",
    "\n",
    "# Select a starting point for predictions\n",
    "input_data_lstm_hybrid = X_test_day[3]\n",
    "input_data_tcn_hybrid = X_test_day[3]\n",
    "\n",
    "# Number of time steps to predict into the future\n",
    "prediction_steps_hybrid = 7\n",
    "\n",
    "# Create the hybrid model\n",
    "hybrid_model_day_attention = create_attention_hybrid_model(lstm_model_day, tcn_model_day)\n",
    "\n",
    "# Train the hybrid model with both LSTM and TCN data\n",
    "hybrid_model_day_attention.fit([X_train_day, X_train_day], y_train_day, epochs=20, batch_size=32, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Mean Squared Error: 0.1476\n",
      "1/1 [==============================] - 1s 725ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Predicted Failures for the Next 7 Time Steps (Hybrid):\n",
      "[0.64054656, 0.66435, 0.67517656, 0.6723426, 0.678719, 0.6767012, 0.66627884]\n",
      "Mean Absolute Error for Predictions: 0.3323\n",
      "Mean Squared Error for Predictions: 0.1106\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using Mean Squared Error\n",
    "mse_day_attention = hybrid_model_day_attention.evaluate([X_test_day, X_test_day], y_test_day, verbose=0)[1]\n",
    "print(f'Model Mean Squared Error: {mse_day_attention:.4f}\\n')\n",
    "\n",
    "# Make predictions with the hybrid model\n",
    "predicted_failures_hybrid_attention = predict_future_failures_hybrid(hybrid_model_day_attention, input_data_lstm_hybrid, input_data_tcn_hybrid, sequence_length, prediction_steps_hybrid)\n",
    "\n",
    "# Print the predicted failures\n",
    "print(\"Predicted Failures for the Next 7 Time Steps (Hybrid):\")\n",
    "print(predicted_failures_hybrid_attention)\n",
    "\n",
    "# Evaluate the predictions using Mean Squared Error\n",
    "mse_predictions = np.mean((predicted_failures_hybrid_attention - y_test_day[3:3+prediction_steps_hybrid])**2)\n",
    "print(f'\\nMean Squared Error for Predictions: {mse_predictions:.4f}\\n')\n",
    "\n",
    "# Evaluate the predictions using Mean Absolute Error\n",
    "mae_predictions_hybrid_attention_day = np.mean(np.abs(predicted_failures_hybrid_attention - y_test_day[3:3+prediction_steps_hybrid]))\n",
    "print(f'Mean Absolute Error for Predictions: {mae_predictions_hybrid_attention_day:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "116/116 [==============================] - 5s 25ms/step - loss: 0.1794 - mean_squared_error: 0.1794 - val_loss: 0.1474 - val_mean_squared_error: 0.1474\n",
      "Epoch 2/10\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 0.1381 - mean_squared_error: 0.1381 - val_loss: 0.1343 - val_mean_squared_error: 0.1343\n",
      "Epoch 3/10\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 0.1370 - mean_squared_error: 0.1370 - val_loss: 0.1258 - val_mean_squared_error: 0.1258\n",
      "Epoch 4/10\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 0.1162 - mean_squared_error: 0.1162 - val_loss: 0.1132 - val_mean_squared_error: 0.1132\n",
      "Epoch 5/10\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 0.1056 - mean_squared_error: 0.1056 - val_loss: 0.1039 - val_mean_squared_error: 0.1039\n",
      "Epoch 6/10\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 0.1029 - mean_squared_error: 0.1029 - val_loss: 0.1001 - val_mean_squared_error: 0.1001\n",
      "Epoch 7/10\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 0.0983 - mean_squared_error: 0.0983 - val_loss: 0.0979 - val_mean_squared_error: 0.0979\n",
      "Epoch 8/10\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 0.0912 - mean_squared_error: 0.0912 - val_loss: 0.0856 - val_mean_squared_error: 0.0856\n",
      "Epoch 9/10\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 0.0872 - mean_squared_error: 0.0872 - val_loss: 0.0932 - val_mean_squared_error: 0.0932\n",
      "Epoch 10/10\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 0.0834 - mean_squared_error: 0.0834 - val_loss: 0.0801 - val_mean_squared_error: 0.0801\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 5s 48ms/step - loss: 0.4476 - mean_squared_error: 0.4476 - val_loss: 0.4064 - val_mean_squared_error: 0.4064\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4470 - mean_squared_error: 0.4470 - val_loss: 0.4064 - val_mean_squared_error: 0.4064\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 40ms/step - loss: 0.4470 - mean_squared_error: 0.4470 - val_loss: 0.4064 - val_mean_squared_error: 0.4064\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4470 - mean_squared_error: 0.4470 - val_loss: 0.4064 - val_mean_squared_error: 0.4064\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 0.4470 - mean_squared_error: 0.4470 - val_loss: 0.4064 - val_mean_squared_error: 0.4064\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4470 - mean_squared_error: 0.4470 - val_loss: 0.4064 - val_mean_squared_error: 0.4064\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4470 - mean_squared_error: 0.4470 - val_loss: 0.4064 - val_mean_squared_error: 0.4064\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4470 - mean_squared_error: 0.4470 - val_loss: 0.4064 - val_mean_squared_error: 0.4064\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4470 - mean_squared_error: 0.4470 - val_loss: 0.4064 - val_mean_squared_error: 0.4064\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.4470 - mean_squared_error: 0.4470 - val_loss: 0.4064 - val_mean_squared_error: 0.4064\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4470 - mean_squared_error: 0.4470 - val_loss: 0.4064 - val_mean_squared_error: 0.4064\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4470 - mean_squared_error: 0.4470 - val_loss: 0.4064 - val_mean_squared_error: 0.4064\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4470 - mean_squared_error: 0.4470 - val_loss: 0.4064 - val_mean_squared_error: 0.4064\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 0.4470 - mean_squared_error: 0.4470 - val_loss: 0.4064 - val_mean_squared_error: 0.4064\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 2s 37ms/step - loss: 0.4470 - mean_squared_error: 0.4470 - val_loss: 0.4064 - val_mean_squared_error: 0.4064\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 2s 38ms/step - loss: 0.4470 - mean_squared_error: 0.4470 - val_loss: 0.4064 - val_mean_squared_error: 0.4064\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 37ms/step - loss: 0.4470 - mean_squared_error: 0.4470 - val_loss: 0.4064 - val_mean_squared_error: 0.4064\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 37ms/step - loss: 0.4470 - mean_squared_error: 0.4470 - val_loss: 0.4064 - val_mean_squared_error: 0.4064\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 2s 37ms/step - loss: 0.4470 - mean_squared_error: 0.4470 - val_loss: 0.4064 - val_mean_squared_error: 0.4064\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 35ms/step - loss: 0.4470 - mean_squared_error: 0.4470 - val_loss: 0.4064 - val_mean_squared_error: 0.4064\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 8s 51ms/step - loss: 0.2161 - mean_squared_error: 0.2161 - val_loss: 0.2138 - val_mean_squared_error: 0.2138\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.2079 - mean_squared_error: 0.2079 - val_loss: 0.2065 - val_mean_squared_error: 0.2065\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.2000 - mean_squared_error: 0.2000 - val_loss: 0.1972 - val_mean_squared_error: 0.1972\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 0.1936 - mean_squared_error: 0.1936 - val_loss: 0.1921 - val_mean_squared_error: 0.1921\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1874 - mean_squared_error: 0.1874 - val_loss: 0.1884 - val_mean_squared_error: 0.1884\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1816 - mean_squared_error: 0.1816 - val_loss: 0.1790 - val_mean_squared_error: 0.1790\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.1774 - mean_squared_error: 0.1774 - val_loss: 0.1743 - val_mean_squared_error: 0.1743\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.1720 - mean_squared_error: 0.1720 - val_loss: 0.1700 - val_mean_squared_error: 0.1700\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.1653 - mean_squared_error: 0.1653 - val_loss: 0.1640 - val_mean_squared_error: 0.1640\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.1597 - mean_squared_error: 0.1597 - val_loss: 0.1572 - val_mean_squared_error: 0.1572\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.1549 - mean_squared_error: 0.1549 - val_loss: 0.1515 - val_mean_squared_error: 0.1515\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.1490 - mean_squared_error: 0.1490 - val_loss: 0.1462 - val_mean_squared_error: 0.1462\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 0.1467 - mean_squared_error: 0.1467 - val_loss: 0.1462 - val_mean_squared_error: 0.1462\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.1449 - mean_squared_error: 0.1449 - val_loss: 0.1432 - val_mean_squared_error: 0.1432\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.1398 - mean_squared_error: 0.1398 - val_loss: 0.1389 - val_mean_squared_error: 0.1389\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.1343 - mean_squared_error: 0.1343 - val_loss: 0.1313 - val_mean_squared_error: 0.1313\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.1316 - mean_squared_error: 0.1316 - val_loss: 0.1290 - val_mean_squared_error: 0.1290\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.1251 - mean_squared_error: 0.1251 - val_loss: 0.1258 - val_mean_squared_error: 0.1258\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 43ms/step - loss: 0.1225 - mean_squared_error: 0.1225 - val_loss: 0.1229 - val_mean_squared_error: 0.1229\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 0.1190 - mean_squared_error: 0.1190 - val_loss: 0.1211 - val_mean_squared_error: 0.1211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f3468e9f010>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare data with hourly intervals\n",
    "data_hour = prepare_data(df_selected, time_intervals['hour'])\n",
    "\n",
    "# Create sequences and targets\n",
    "sequences_hour, targets_hour = create_sequences(data_hour, sequence_length)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_hour, X_test_hour, y_train_hour, y_test_hour = train_test_split(sequences_hour, targets_hour, test_size=0.2, random_state=1)\n",
    "\n",
    "# Build the LSTM model\n",
    "lstm_model_hour = Sequential()\n",
    "lstm_model_hour.add(LSTM(50, input_shape=(X_train_hour.shape[1], X_train_hour.shape[2])))\n",
    "lstm_model_hour.add(Dense(1, activation='sigmoid'))\n",
    "lstm_model_hour.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
    "\n",
    "# Train the model\n",
    "lstm_model_hour.fit(X_train_hour, y_train_hour, epochs=10, batch_size=16, validation_split=0.15)\n",
    "\n",
    "# Build the TCN model\n",
    "tcn_model_hour = Sequential([\n",
    "    TCN(input_shape=(sequence_length, X_train_hour.shape[2])),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "tcn_model_hour.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
    "\n",
    "# Train the model\n",
    "tcn_model_hour.fit(X_train_hour, y_train_hour, epochs=20, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Function to create a hybrid model with attention mechanism\n",
    "def create_attention_hybrid_model(lstm_model, tcn_model):\n",
    "    lstm_input = lstm_model.input\n",
    "    tcn_input = tcn_model.input\n",
    "\n",
    "    # Get the output layers of both models\n",
    "    lstm_output = lstm_model.layers[-1].output\n",
    "    tcn_output = tcn_model.layers[-1].output\n",
    "\n",
    "    # Use Attention mechanism to combine outputs\n",
    "    attention = Attention()([lstm_output, tcn_output])\n",
    "    merged = Concatenate()([lstm_output, tcn_output, attention])\n",
    "\n",
    "    # Add a dense layer for the final prediction\n",
    "    merged = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "    # Create the ensemble model\n",
    "    ensemble_model = Model(inputs=[lstm_input, tcn_input], outputs=merged)\n",
    "\n",
    "    # Compile the model\n",
    "    ensemble_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
    "\n",
    "    return ensemble_model\n",
    "\n",
    "# Select a starting point for predictions\n",
    "input_data_lstm_hybrid = X_test_hour[3]\n",
    "input_data_tcn_hybrid = X_test_hour[3]\n",
    "\n",
    "# Number of time steps to predict into the future\n",
    "prediction_steps_hybrid = 7\n",
    "\n",
    "# Create the hybrid model\n",
    "hybrid_model_hour_attention = create_attention_hybrid_model(lstm_model_hour, tcn_model_hour)\n",
    "\n",
    "# Train the hybrid model with both LSTM and TCN data\n",
    "hybrid_model_hour_attention.fit([X_train_hour, X_train_hour], y_train_hour, epochs=20, batch_size=32, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Mean Squared Error: 0.1275\n",
      "\n",
      "1/1 [==============================] - 1s 697ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Predicted Failures for the Next 7 Time Steps (Hybrid):\n",
      "[0.3634331, 0.3227131, 0.3204667, 0.3197397, 0.31916603, 0.31874532, 0.31914416]\n",
      "Mean Absolute Error for Predictions: 0.4169\n",
      "\n",
      "Mean Squared Error for Predictions: 0.1973\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using Mean Squared Error\n",
    "mse_hour_attention = hybrid_model_hour_attention.evaluate([X_test_hour, X_test_hour], y_test_hour, verbose=0)[1]\n",
    "print(f'Model Mean Squared Error: {mse_hour_attention:.4f}\\n')\n",
    "\n",
    "# Make predictions with the hybrid model\n",
    "predicted_failures_hybrid_attention = predict_future_failures_hybrid(hybrid_model_hour_attention, input_data_lstm_hybrid, input_data_tcn_hybrid, sequence_length, prediction_steps_hybrid)\n",
    "\n",
    "# Print the predicted failures\n",
    "print(\"Predicted Failures for the Next 7 Time Steps (Hybrid):\")\n",
    "print(predicted_failures_hybrid_attention)\n",
    "\n",
    "# Evaluate the predictions using Mean Squared Error\n",
    "mse_predictions = np.mean((predicted_failures_hybrid_attention - y_test_hour[3:3+prediction_steps_hybrid])**2)\n",
    "print(f'\\nMean Squared Error for Predictions: {mse_predictions:.4f}\\n')\n",
    "\n",
    "# Evaluate the predictions using Mean Absolute Error\n",
    "mae_predictions_hybrid_attention_hour = np.mean(np.abs(predicted_failures_hybrid_attention - y_test_hour[3:3+prediction_steps_hybrid]))\n",
    "print(f'Mean Absolute Error for Predictions: {mae_predictions_hybrid_attention_hour:.4f}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 516/7033 [=>............................] - ETA: 2:13 - loss: 0.0309 - mean_squared_error: 0.0309"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m lstm_model_minute\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[43mlstm_model_minute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_minute\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_minute\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.15\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Build the TCN model\u001b[39;00m\n\u001b[1;32m     20\u001b[0m tcn_model_minute \u001b[38;5;241m=\u001b[39m Sequential([\n\u001b[1;32m     21\u001b[0m     TCN(input_shape\u001b[38;5;241m=\u001b[39m(sequence_length, X_train_minute\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m])),\n\u001b[1;32m     22\u001b[0m     Dense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     23\u001b[0m ])\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/keras/src/engine/training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1777\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1783\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1785\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:140\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21merror_handler\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    139\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mis_traceback_filtering_enabled\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    141\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    142\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNameError\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;66;03m# In some very rare cases,\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;66;03m# `is_traceback_filtering_enabled` (from the outer scope) may not be\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;66;03m# accessible from inside this function\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:47\u001b[0m, in \u001b[0;36mis_traceback_filtering_enabled\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdebugging.is_traceback_filtering_enabled\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_traceback_filtering_enabled\u001b[39m():\n\u001b[1;32m     34\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Check whether traceback filtering is currently enabled.\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;03m  See also `tf.debugging.enable_traceback_filtering()` and\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;124;03m    was called).\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m   value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_ENABLE_TRACEBACK_FILTERING, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     48\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "data_minute = prepare_data(df_selected, time_intervals['minute'])\n",
    "\n",
    "# Create sequences and targets\n",
    "sequences_minute, targets_minute = create_sequences(data_minute, sequence_length)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_minute, X_test_minute, y_train_minute, y_test_minute = train_test_split(sequences_minute, targets_minute, test_size=0.2, random_state=1)\n",
    "\n",
    "# Build the LSTM model\n",
    "lstm_model_minute = Sequential()\n",
    "lstm_model_minute.add(LSTM(50, input_shape=(X_train_minute.shape[1], X_train_minute.shape[2])))\n",
    "lstm_model_minute.add(Dense(1, activation='sigmoid'))\n",
    "lstm_model_minute.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
    "\n",
    "# Train the model\n",
    "lstm_model_minute.fit(X_train_minute, y_train_minute, epochs=10, batch_size=16, validation_split=0.15)\n",
    "\n",
    "# Build the TCN model\n",
    "tcn_model_minute = Sequential([\n",
    "    TCN(input_shape=(sequence_length, X_train_minute.shape[2])),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "tcn_model_minute.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
    "\n",
    "# Train the model\n",
    "tcn_model_minute.fit(X_train_minute, y_train_minute, epochs=20, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Function to create a hybrid model with attention mechanism\n",
    "def create_attention_hybrid_model(lstm_model, tcn_model):\n",
    "    lstm_input = lstm_model.input\n",
    "    tcn_input = tcn_model.input\n",
    "\n",
    "    # Get the output layers of both models\n",
    "    lstm_output = lstm_model.layers[-1].output\n",
    "    tcn_output = tcn_model.layers[-1].output\n",
    "\n",
    "    # Use Attention mechanism to combine outputs\n",
    "    attention = Attention()([lstm_output, tcn_output])\n",
    "    merged = Concatenate()([lstm_output, tcn_output, attention])\n",
    "\n",
    "    # Add a dense layer for the final prediction\n",
    "    merged = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "    # Create the ensemble model\n",
    "    ensemble_model = Model(inputs=[lstm_input, tcn_input], outputs=merged)\n",
    "\n",
    "    # Compile the model\n",
    "    ensemble_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
    "\n",
    "    return ensemble_model\n",
    "\n",
    "# Select a starting point for predictions\n",
    "input_data_lstm_hybrid = X_test_minute[3]\n",
    "input_data_tcn_hybrid = X_test_minute[3]\n",
    "\n",
    "# Number of time steps to predict into the future\n",
    "prediction_steps_hybrid = 7\n",
    "\n",
    "# Create the hybrid model\n",
    "hybrid_model_minute_attention = create_attention_hybrid_model(lstm_model_minute, tcn_model_minute)\n",
    "\n",
    "# Train the hybrid model with both LSTM and TCN data\n",
    "hybrid_model_minute_attention.fit([X_train_minute, X_train_minute], y_train_minute, epochs=10, batch_size=32, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Mean Squared Error: 0.0013\n",
      "\n",
      "1/1 [==============================] - 1s 717ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Predicted Failures for the Next 7 Time Steps (Hybrid):\n",
      "[0.0026827534, 0.0026833082, 0.0026832204, 0.0026832472, 0.0026831846, 0.0026832088, 0.0026832088]\n",
      "\n",
      "Mean Squared Error for Predictions: 0.4263\n",
      "\n",
      "Mean Absolute Error for Predictions: 0.4290\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using Mean Squared Error\n",
    "mse_minute_attention = hybrid_model_minute_attention.evaluate([X_test_minute, X_test_minute], y_test_minute, verbose=0)[1]\n",
    "print(f'Model Mean Squared Error: {mse_minute_attention:.4f}\\n')\n",
    "\n",
    "# Make predictions with the hybrid model\n",
    "predicted_failures_hybrid_attention = predict_future_failures_hybrid(hybrid_model_minute_attention, input_data_lstm_hybrid, input_data_tcn_hybrid, sequence_length, prediction_steps_hybrid)\n",
    "\n",
    "# Print the predicted failures\n",
    "print(\"Predicted Failures for the Next 7 Time Steps (Hybrid):\")\n",
    "print(predicted_failures_hybrid_attention)\n",
    "\n",
    "# Evaluate the predictions using Mean Squared Error\n",
    "mse_predictions = np.mean((predicted_failures_hybrid_attention - y_test_minute[3:3+prediction_steps_hybrid])**2)\n",
    "print(f'\\nMean Squared Error for Predictions: {mse_predictions:.4f}\\n')\n",
    "\n",
    "# Evaluate the predictions using Mean Absolute Error\n",
    "mae_predictions_hybrid_attention_minute = np.mean(np.abs(predicted_failures_hybrid_attention - y_test_minute[3:3+prediction_steps_hybrid]))\n",
    "print(f'Mean Absolute Error for Predictions: {mae_predictions_hybrid_attention_minute:.4f}\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
